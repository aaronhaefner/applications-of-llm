{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for demonstrating generative text with fine-tuned language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "load_dotenv()\n",
    "\n",
    "from code.models.torch_llm import create_pipeline, generate_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning regarding `clean_up_tokenization_spaces` has been suppressed. Refer to the Hugging Face issue for more details: https://github.com/huggingface/transformers/issues/31884\n"
     ]
    }
   ],
   "source": [
    "# Suppress specific warning and print info\n",
    "warnings.filterwarnings(\n",
    "    'ignore',\n",
    "    message=r'`clean_up_tokenization_spaces` was not set',\n",
    "    category=FutureWarning\n",
    ")\n",
    "\n",
    "print(\"Warning regarding `clean_up_tokenization_spaces` has been suppressed. Refer to the Hugging Face issue for details: https://github.com/huggingface/transformers/issues/31884\")\n",
    "\n",
    "# Load the model\n",
    "model_name = \"EleutherAI/gpt-neo-1.3B\"\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "task = \"text-generation\"\n",
    "pipe = create_pipeline(task, model_name, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The future of AI is already here - here's how it's making life better\\n\\nThis article originally appeared in New Scientist and has been translated and edited for the Tech Insider Network.\\n\\nOn the front lines of the artificial intelligence revolution are some\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate text with prompts\n",
    "prompt = \"The future of AI is\"\n",
    "generate_text(pipe, prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
